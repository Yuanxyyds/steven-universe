# Model Presets Configuration
# Maps model_id + task_preset to Docker execution parameters
#
# Structure:
#   models:
#     {model_id}:
#       {task_preset}:
#         docker_image: Docker image to use
#         command: Command to execute in container
#         env_vars: Environment variables to set
#
# Note: Volume mounts for models are added dynamically by the server
# based on model_cache_manager's fetched path.

models:
  # =========================================================================
  # LLaMA Models
  # =========================================================================

  llama-7b:
    inference:
      docker_image: "llm-runner:latest"
      command: ["python", "inference.py"]
      env_vars:
        MODEL_NAME: "llama-7b"
        MODEL_TYPE: "llama"

    training:
      docker_image: "llm-trainer:latest"
      command: ["python", "train.py"]
      env_vars:
        MODEL_NAME: "llama-7b"
        MODEL_TYPE: "llama"
        TRAINING_MODE: "full"

  llama-13b:
    inference:
      docker_image: "llm-runner:latest"
      command: ["python", "inference.py"]
      env_vars:
        MODEL_NAME: "llama-13b"
        MODEL_TYPE: "llama"

    training:
      docker_image: "llm-trainer:latest"
      command: ["python", "train.py"]
      env_vars:
        MODEL_NAME: "llama-13b"
        MODEL_TYPE: "llama"
        TRAINING_MODE: "full"

  # =========================================================================
  # Stable Diffusion Models
  # =========================================================================

  stable-diffusion-xl:
    inference:
      docker_image: "sd-runner:latest"
      command: ["python", "generate.py"]
      env_vars:
        MODEL_NAME: "sdxl"
        MODEL_TYPE: "diffusion"

    training:
      docker_image: "sd-trainer:latest"
      command: ["python", "finetune.py"]
      env_vars:
        MODEL_NAME: "sdxl"
        MODEL_TYPE: "diffusion"

  stable-diffusion-v2:
    inference:
      docker_image: "sd-runner:latest"
      command: ["python", "generate.py"]
      env_vars:
        MODEL_NAME: "sd-v2"
        MODEL_TYPE: "diffusion"

  # =========================================================================
  # GPT Models
  # =========================================================================

  gpt2-medium:
    inference:
      docker_image: "gpt-runner:latest"
      command: ["python", "inference.py"]
      env_vars:
        MODEL_NAME: "gpt2-medium"
        MODEL_TYPE: "gpt"

    training:
      docker_image: "gpt-trainer:latest"
      command: ["python", "train.py"]
      env_vars:
        MODEL_NAME: "gpt2-medium"
        MODEL_TYPE: "gpt"

  # =========================================================================
  # Example: Custom Models
  # =========================================================================

  custom-model-example:
    inference:
      docker_image: "custom-runner:v1"
      command: ["python", "run_inference.py", "--mode", "fast"]
      env_vars:
        MODEL_NAME: "custom-model"
        BATCH_SIZE: "8"
        USE_FP16: "true"

    preprocessing:
      docker_image: "data-processor:latest"
      command: ["python", "preprocess.py"]
      env_vars:
        MODEL_NAME: "custom-model"
        TASK_TYPE: "preprocessing"

# =========================================================================
# Configuration Guidelines:
# =========================================================================
#
# 1. Model IDs:
#    - Use lowercase with hyphens
#    - Be descriptive: "llama-7b" not "llama7b"
#    - Include version/size when relevant
#
# 2. Task Presets:
#    - Common presets: inference, training, preprocessing
#    - Use consistent naming across models
#    - Document any custom presets
#
# 3. Docker Images:
#    - Use specific tags (not :latest in production)
#    - Ensure images are available in your registry
#    - Test images independently before adding here
#
# 4. Commands:
#    - Use absolute paths or ensure PATH is set
#    - Keep commands simple (complex logic in scripts)
#    - Pass parameters via env vars when possible
#
# 5. Environment Variables:
#    - MODEL_NAME: Required for most workers
#    - MODEL_PATH: Set automatically by server (points to /models)
#    - Add only variables needed by the worker
#
# 6. Volume Mounts:
#    - Model volumes added automatically by server
#    - Additional mounts can be added in future versions
#    - Current: /data/models/{model_id} â†’ /models (read-only)
