# === VM Deployment Configuration ===
VM_HOST=root@192.168.1.105
DEPLOY_PATH=~/gpu-server

# === Application Configuration ===
APP_NAME=GPU Service
APP_VERSION=1.0.0
LOG_LEVEL=INFO

# === CORS Configuration ===
CORS_ORIGINS=http://localhost:3000,https://liustev6.ca

# === GPU Configuration ===
GPU_DEVICE_IDS=0,1
GPU_DEVICE_DIFFICULTY=0:low,1:high
GPU_METRICS_REFRESH_INTERVAL=5

# === Session Configuration ===
SESSION_IDLE_TIMEOUT_SECONDS=300
SESSION_MAX_LIFETIME_SECONDS=3600
SESSION_QUEUE_MAX_SIZE=5
SESSION_MONITOR_INTERVAL=30

# === Task Configuration ===
DEFAULT_TASK_TIMEOUT=300
MAX_TASK_TIMEOUT=1800
TASK_MEMORY_LIMIT=16g
TASK_CPU_QUOTA=100000

# === Legacy Job Configuration (backward compatibility) ===
DEFAULT_JOB_TIMEOUT=3600
MAX_JOB_TIMEOUT=86400
MAX_QUEUE_SIZE=10
JOB_MEMORY_LIMIT=16g
JOB_CPU_QUOTA=100000

# === Docker Configuration ===
DOCKER_SOCKET_PATH=/var/run/docker.sock
ALLOWED_DOCKER_IMAGES=pytorch/pytorch:*,tensorflow/tensorflow:*,nvcr.io/nvidia/*

# === Model Cache Configuration ===
MODEL_CACHE_DIR=/data/models
AUTO_FETCH_MODELS=true

# === File Service Integration ===
FILE_SERVICE_URL=http://192.168.2.98:8000
FILE_SERVICE_INTERNAL_KEY=your-internal-secret-key-here

# === Authentication ===
INTERNAL_API_KEY=your-internal-api-key-here
